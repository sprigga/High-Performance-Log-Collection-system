# FastAPI çš„è§’è‰²å’Œä½œç”¨

æœ¬æ–‡æª”è©³ç´°èªªæ˜ FastAPI åœ¨é«˜æ•ˆèƒ½æ—¥èªŒæ”¶é›†ç³»çµ±ä¸­çš„æ ¸å¿ƒè§’è‰²èˆ‡åŠŸèƒ½ã€‚

## ğŸ¯ FastAPI çš„æ ¸å¿ƒè§’è‰²

### 1. **é«˜æ•ˆèƒ½ API æœå‹™å±¤** (app/main.py)

FastAPI ä½œç‚ºæ•´å€‹ç³»çµ±çš„å‰ç«¯ API æœå‹™ï¼Œè² è²¬:

- æ¥æ”¶ä¾†è‡ªè¨­å‚™çš„æ—¥èªŒè«‹æ±‚ (POST /api/log)
- è™•ç†æ‰¹é‡æ—¥èªŒ (POST /api/logs/batch)
- æä¾›æ—¥èªŒæŸ¥è©¢æœå‹™ (GET /api/logs/{device_id})
- ç³»çµ±çµ±è¨ˆè³‡æ–™ (GET /api/stats)
- å¥åº·æª¢æŸ¥ (GET /health)
- Prometheus ç›£æ§æŒ‡æ¨™ (GET /metrics)

### 2. **éåŒæ­¥è™•ç†å¼•æ“**

```python
# main.py:11-15
from fastapi import FastAPI, Depends, HTTPException, Query, Response
from fastapi.responses import JSONResponse
from sqlalchemy.ext.asyncio import AsyncSession
```

**ç‰¹é»:**
- ä½¿ç”¨ `async/await` éé˜»å¡ I/O æ¨¡å¼
- æ­é… AsyncSession é€²è¡Œç•°æ­¥è³‡æ–™åº«æ“ä½œ
- æ”¯æ´é«˜ä¸¦ç™¼è«‹æ±‚è™•ç† (~23,895 logs/sec)

### 3. **å¿«é€Ÿå›æ‡‰æ©Ÿåˆ¶** (app/main.py:186-243)

```python
@app.post("/api/log", response_model=LogEntryResponse)
async def create_log(log: LogEntryRequest):
    # 1. é©—è­‰è³‡æ–™
    # 2. å¯«å…¥ Redis Stream (éåŒæ­¥ä½‡åˆ—)
    # 3. ç«‹å³è¿”å› "queued" ç‹€æ…‹ (< 5ms)
```

**é—œéµæµç¨‹:**

```
1. æ¥æ”¶æ—¥èªŒ â†’ 2. å¯«å…¥ Redis Stream â†’ 3. ç«‹å³è¿”å› â†’ 4. (Worker èƒŒæ™¯è™•ç†)
```

é€™ç¨®æ¶æ§‹è®“ FastAPI å¯ä»¥:
- âœ… å¿«é€Ÿå›æ‡‰å®¢æˆ¶ç«¯ (P95: ~60ms)
- âœ… ä¸è¢«è³‡æ–™åº«å¯«å…¥é€Ÿåº¦é™åˆ¶
- âœ… å°‡è€—æ™‚æ“ä½œäº¤çµ¦ Worker è™•ç†

### 4. **è² è¼‰åˆ†æ•£çš„æ¥æ”¶ç«¯** (2 å€‹å¯¦ä¾‹)

```yaml
# docker-compose.yml
fastapi-1:
  command: uvicorn main:app --host 0.0.0.0 --port 8000 --workers 6
fastapi-2:
  command: uvicorn main:app --host 0.0.0.0 --port 8000 --workers 6
```

é€é Nginx è² è¼‰å¹³è¡¡åˆ†é…è«‹æ±‚åˆ°:
- FastAPI Instance 1 (6 workers)
- FastAPI Instance 2 (6 workers)
- **ç¸½è¨ˆ 12 å€‹ worker processes**

### 5. **æ™ºèƒ½å¿«å–å±¤** (app/main.py:320-406)

```python
@app.get("/api/logs/{device_id}", response_model=BatchLogQueryResponse)
async def get_logs(...):
    # 1. å…ˆæŸ¥ Redis å¿«å–
    cached_data = await redis_client.get(cache_key)

    if cached_data:
        # Cache Hit - ç›´æ¥è¿”å›
        return BatchLogQueryResponse(source="cache", ...)
    else:
        # Cache Miss - æŸ¥è©¢è³‡æ–™åº«
        result = await db.execute(query)

        # 3. å¯«å…¥å¿«å– (TTL 5åˆ†é˜)
        await redis_client.setex(cache_key, 300, json.dumps(logs_data))
```

**æ•ˆç›Š:**
- æ¸›å°‘è³‡æ–™åº«è² è¼‰
- æå‡æŸ¥è©¢æ•ˆèƒ½
- Cache Hit å›æ‡‰æ™‚é–“ < 10ms

### 6. **å®Œæ•´çš„ç›£æ§æ•´åˆ** (app/metrics.py)

```python
# main.py:24-38
from metrics import (
    MetricsMiddleware,
    logs_received_total,
    redis_stream_messages_total,
    redis_cache_hits_total,
    redis_cache_misses_total,
    # ... æ›´å¤šæŒ‡æ¨™
)

# main.py:50
app.add_middleware(MetricsMiddleware)
```

**æä¾› Prometheus æ ¼å¼çš„æŒ‡æ¨™:**
- HTTP è«‹æ±‚çµ±è¨ˆ (QPS, å»¶é², ç‹€æ…‹ç¢¼)
- Redis æ“ä½œæ™‚é–“ (XADD, GET, SET, XREADGROUP)
- æ¥­å‹™æŒ‡æ¨™ (logs_received_total, logs_by_level)
- ç³»çµ±è³‡æºç›£æ§ (CPU, Memory, Disk)

---

## ğŸ“Š æ¶æ§‹å®šä½

```
å®¢æˆ¶ç«¯è£ç½® (100 units)
    â†“
Nginx è² è¼‰å¹³è¡¡å™¨ [:18723]
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ FastAPI (2 instances Ã— 6 workers)â”‚  â† FastAPI åœ¨æ­¤ä½ç½®
â”‚ - å¿«é€Ÿæ¥æ”¶è«‹æ±‚                   â”‚
â”‚ - å¯«å…¥ Redis Stream             â”‚
â”‚ - ç«‹å³è¿”å› "queued"             â”‚
â”‚ - æŸ¥è©¢æ™‚ä½¿ç”¨å¿«å–                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
Redis Stream (è¨Šæ¯ä½‡åˆ—)
    â†“
Worker (æ‰¹æ¬¡è™•ç†)
    â†“
PostgreSQL (æŒä¹…åŒ–å„²å­˜)
```

---

## ğŸ”„ API ç«¯é»èˆ‡åŠŸèƒ½å°ç…§è¡¨

| Method | Endpoint | åŠŸèƒ½èªªæ˜ | æª”æ¡ˆä½ç½® | å›æ‡‰æ™‚é–“ |
|--------|----------|----------|----------|----------|
| GET | `/` | æœå‹™è³‡è¨Š | main.py:496-513 | < 1ms |
| GET | `/health` | å¥åº·æª¢æŸ¥ (Redis + PostgreSQL) | main.py:146-182 | < 10ms |
| POST | `/api/log` | å–®ç­†æ—¥èªŒå¯«å…¥ | main.py:187-243 | < 5ms |
| POST | `/api/logs/batch` | æ‰¹é‡æ—¥èªŒå¯«å…¥ (1-1000ç­†) | main.py:248-315 | < 20ms |
| GET | `/api/logs/{device_id}` | æŸ¥è©¢è¨­å‚™æ—¥èªŒ (å«å¿«å–) | main.py:320-406 | 10-50ms |
| GET | `/api/stats` | ç³»çµ±çµ±è¨ˆ (å¿«å–60ç§’) | main.py:411-482 | < 10ms |
| GET | `/metrics` | Prometheus æŒ‡æ¨™ | main.py:487-493 | < 5ms |
| GET | `/docs` | Swagger UI æ–‡æª” | è‡ªå‹•ç”Ÿæˆ | - |
| GET | `/redoc` | ReDoc æ–‡æª” | è‡ªå‹•ç”Ÿæˆ | - |

---

## ğŸ¯ ç‚ºä½•é¸æ“‡ FastAPIï¼Ÿ

### 1. **åŸç”Ÿç•°æ­¥æ”¯æ´**
```python
# æ”¯æ´ async/await èªæ³•
async def create_log(log: LogEntryRequest):
    await redis_client.xadd(...)
    return response
```

### 2. **è‡ªå‹•æ–‡æª”ç”Ÿæˆ**
- Swagger UI: http://localhost:18723/docs
- ReDoc: http://localhost:18723/redoc
- ç„¡éœ€é¡å¤–ç¶­è­· API æ–‡æª”

### 3. **è³‡æ–™é©—è­‰**
```python
# ä½¿ç”¨ Pydantic è‡ªå‹•é©—è­‰
class LogEntryRequest(BaseModel):
    device_id: str = Field(..., max_length=50)
    log_level: str = Field(..., pattern="^(DEBUG|INFO|WARNING|ERROR|CRITICAL)$")
    message: str = Field(..., max_length=1000)
    log_data: Optional[Dict[str, Any]] = None
```

### 4. **é«˜æ•ˆèƒ½**
- åŸºæ–¼ Starlette å’Œ Pydantic
- æ•ˆèƒ½æ¥è¿‘ Node.js å’Œ Go
- å¯¦æ¸¬ååé‡: ~23,895 logs/sec

### 5. **ç¾ä»£åŒ–é–‹ç™¼é«”é©—**
- åŸºæ–¼ Python 3.11+ å’Œ Type Hints
- IDE è‡ªå‹•è£œå…¨æ”¯æ´
- é¡å‹æª¢æŸ¥ (mypy)

---

## ğŸš€ æ•ˆèƒ½å„ªåŒ–ç­–ç•¥

### 1. **é€£ç·šæ± ç®¡ç†**

#### Redis é€£ç·šæ±  (main.py:88-96)
```python
pool = redis.ConnectionPool(
    host=REDIS_HOST,
    port=REDIS_PORT,
    decode_responses=True,
    max_connections=200  # æ”¯æ´é«˜ä¸¦ç™¼
)
redis_client = redis.Redis(connection_pool=pool)
```

#### PostgreSQL é€£ç·šæ±  (database.py:40-45)
```python
async_engine = create_async_engine(
    ASYNC_DATABASE_URL,
    pool_size=10,        # æŒä¹…é€£ç·šæ•¸
    max_overflow=5,      # é¡å¤–é€£ç·šæ•¸
    pool_pre_ping=True,  # é€£ç·šå‰æª¢æŸ¥
    pool_recycle=3600    # 1å°æ™‚å›æ”¶
)
```

### 2. **æ‰¹æ¬¡è™•ç† API** (main.py:248-315)

```python
@app.post("/api/logs/batch")
async def create_batch_logs(batch: BatchLogEntryRequest):
    # ä½¿ç”¨ Redis Pipeline æ‰¹æ¬¡å¯«å…¥
    pipe = redis_client.pipeline()

    for log in batch.logs:
        pipe.xadd(name="logs:stream", fields=log_dict, ...)

    # ä¸€æ¬¡åŸ·è¡Œæ‰€æœ‰æ“ä½œ (æ¸›å°‘ç¶²è·¯å¾€è¿”)
    results = await pipe.execute()
```

**æ•ˆç›Š:**
- æ¸›å°‘ç¶²è·¯å¾€è¿”æ¬¡æ•¸
- æå‡ååé‡è‡³ 10,000+ logs/sec
- é™ä½å¹³å‡å»¶é²

### 3. **èƒŒæ™¯ä»»å‹™** (main.py:65-77)

```python
async def update_metrics_task():
    """å®šæœŸæ›´æ–°ç³»çµ±æŒ‡æ¨™"""
    while True:
        update_system_metrics()
        if redis_client:
            stream_len = await redis_client.xlen('logs:stream')
            redis_stream_size.set(stream_len)
        await asyncio.sleep(10)  # æ¯ 10 ç§’æ›´æ–°
```

### 4. **ä¸­é–“ä»¶** (metrics.py:130-194)

```python
class MetricsMiddleware(BaseHTTPMiddleware):
    async def dispatch(self, request, call_next):
        start_time = time.time()

        # è™•ç†è«‹æ±‚
        response = await call_next(request)

        # è¨˜éŒ„æŒ‡æ¨™
        duration = time.time() - start_time
        http_request_duration_seconds.labels(
            method=request.method,
            endpoint=request.url.path,
            status=response.status_code
        ).observe(duration)

        return response
```

---

## ğŸ”§ FastAPI èˆ‡ Worker çš„åˆ†å·¥

### FastAPI çš„è·è²¬:
- âœ… **æ¥æ”¶è«‹æ±‚** - é©—è­‰è³‡æ–™æ ¼å¼
- âœ… **å¯«å…¥ Redis Stream** - éåŒæ­¥ä½‡åˆ—
- âœ… **ç«‹å³è¿”å›** - å›æ‡‰å®¢æˆ¶ç«¯ (< 5ms)
- âœ… **æŸ¥è©¢æœå‹™** - ä½¿ç”¨å¿«å–åŠ é€Ÿ
- âœ… **ç›£æ§æŒ‡æ¨™** - æ”¶é›†ä¸¦æš´éœ² Prometheus metrics

### Worker çš„è·è²¬ (app/worker.py):
- âœ… **æ¶ˆè²»è¨Šæ¯** - å¾ Redis Stream è®€å–
- âœ… **æ‰¹æ¬¡å¯«å…¥** - 100 ç­†ä¸€æ‰¹å¯«å…¥ PostgreSQL
- âœ… **ACK ç¢ºèª** - ç¢ºä¿è¨Šæ¯ä¸éºå¤±
- âœ… **éŒ¯èª¤é‡è©¦** - å¤±æ•—è‡ªå‹•é‡è©¦

### æµç¨‹åœ–:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Client  â”‚â”€â”€â”€â”€â–¶â”‚ FastAPI â”‚â”€â”€â”€â”€â–¶â”‚ Redis Stream  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚                    â”‚
                      â”‚ (ç«‹å³è¿”å›)          â”‚
                      â–¼                    â–¼
                 200 OK              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                 {queued}            â”‚ Worker  â”‚
                                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                          â”‚
                                          â–¼
                                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                    â”‚PostgreSQLâ”‚
                                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“ˆ å¯¦éš›æ•ˆèƒ½æ•¸æ“š

### å£“åŠ›æ¸¬è©¦çµæœ (50 æ¬¡è¿­ä»£)

**æ¸¬è©¦ç’°å¢ƒ:**
- CPU: Apple Silicon (ARM64)
- Memory: 16 GB RAM
- Storage: SSD (NVMe)
- OS: macOS

**æ¸¬è©¦é…ç½®:**
- æ¨¡æ“¬è¨­å‚™: 100 å°
- æ¯æ¬¡è¿­ä»£æ—¥èªŒæ•¸: 10,000 ç­†
- ä¸¦ç™¼é€£ç·š: 200
- æ‰¹æ¬¡å¤§å°: 5 ç­†/è«‹æ±‚
- ç¸½è«‹æ±‚æ•¸: 100,000 (å…¨éƒ¨æˆåŠŸ)
- ç¸½æ—¥èªŒæ•¸: 500,000

**å¯¦æ¸¬æ•ˆèƒ½:**

| æŒ‡æ¨™ | ç›®æ¨™ | å¯¦éš›é”æˆ | ç‹€æ…‹ |
|------|------|----------|------|
| ååé‡ | â‰¥ 10,000 logs/sec | ~23,895 logs/sec å¹³å‡ | âœ… 2.39x |
| P95 å»¶é² | â‰¤ 100 ms | ~60.57 ms å¹³å‡ | âœ… é”æ¨™ |
| P99 å»¶é² | < 500 ms | ~96.15 ms å¹³å‡ | âœ… 5.20x |
| éŒ¯èª¤ç‡ | 0% | 0% | âœ… å®Œç¾ |
| å¹³å‡å›æ‡‰æ™‚é–“ | - | 18.33 ms | âœ… å„ªç•° |

### æ•ˆèƒ½åˆ†ä½ˆ:
```
â€¢ æœ€å¿«å›æ‡‰æ™‚é–“: 1.06 ms
â€¢ æœ€æ…¢å›æ‡‰æ™‚é–“: 248.77 ms
â€¢ P50 (ä¸­ä½æ•¸): 13.54 ms
â€¢ P95: 60.57 ms (ç¯„åœ: 33.93 - 107.07 ms)
â€¢ P99: 96.15 ms (ç¯„åœ: 58.28 - 228.83 ms)
```

### ç›®æ¨™é”æˆç‡:
- âœ… ååé‡ç›®æ¨™é”æˆ: 50/50 æ¬¡è¿­ä»£ (100%)
- âœ… P95 å»¶é²ç›®æ¨™é”æˆ: 47/50 æ¬¡è¿­ä»£ (94%)
- âœ… é›¶éŒ¯èª¤ç‡: 50/50 æ¬¡è¿­ä»£ (100%)

---

## ğŸ› ï¸ é…ç½®åƒæ•¸èªªæ˜

### æ‡‰ç”¨ç¨‹å¼è¨­å®š

```python
# main.py:43-47
app = FastAPI(
    title="é«˜æ•ˆèƒ½æ—¥èªŒæ”¶é›†ç³»çµ±",
    description="åŸºæ–¼ FastAPI + Redis + PostgreSQL çš„æ—¥èªŒæ”¶é›†ç³»çµ±",
    version="1.0.0"
)
```

### å¯¦ä¾‹è¨­å®š

```bash
# ç’°å¢ƒè®Šæ•¸
INSTANCE_NAME=fastapi-1          # å¯¦ä¾‹è­˜åˆ¥åç¨±
REDIS_HOST=localhost             # Redis ä¸»æ©Ÿ
REDIS_PORT=6379                  # Redis åŸ è™Ÿ
TZ=Asia/Taipei                   # æ™‚å€è¨­å®š
```

### Worker æ•¸é‡è¨­å®š

```yaml
# docker-compose.yml
fastapi-1:
  command: uvicorn main:app --host 0.0.0.0 --port 8000 --workers 6
```

**å»ºè­°å€¼:**
- CPU å¯†é›†å‹: `workers = CPUæ ¸å¿ƒæ•¸ + 1`
- I/O å¯†é›†å‹: `workers = (2 Ã— CPUæ ¸å¿ƒæ•¸) + 1`
- æœ¬å°ˆæ¡ˆä½¿ç”¨: 6 workers (I/O å¯†é›†å‹)

---

## ğŸ“š ç›¸é—œæ–‡ä»¶

- [README.md](../README.md) - å°ˆæ¡ˆç¸½è¦½
- [app/main.py](../app/main.py) - FastAPI ä¸»æ‡‰ç”¨ç¨‹å¼
- [app/worker.py](../app/worker.py) - èƒŒæ™¯ Worker
- [app/models.py](../app/models.py) - è³‡æ–™æ¨¡å‹
- [app/metrics.py](../app/metrics.py) - ç›£æ§æŒ‡æ¨™

---

## ğŸ“ ç¸½çµ

FastAPI åœ¨é€™å€‹å°ˆæ¡ˆä¸­æ‰®æ¼” **é«˜ååé‡ API é–˜é“** çš„è§’è‰²:

1. âœ… **å¿«é€Ÿæ¥æ”¶** - < 5ms å¯«å…¥ Redis Stream
2. âœ… **éåŒæ­¥è™•ç†** - async/await éé˜»å¡æ¨¡å¼
3. âœ… **æ™ºèƒ½å¿«å–** - Redis å¿«å–é™ä½è³‡æ–™åº«å£“åŠ›
4. âœ… **å®Œæ•´ç›£æ§** - Prometheus æŒ‡æ¨™æ•´åˆ
5. âœ… **æ°´å¹³æ“´å±•** - æ”¯æ´å¤šå¯¦ä¾‹éƒ¨ç½²
6. âœ… **é«˜å¯ç”¨æ€§** - å¥åº·æª¢æŸ¥èˆ‡è‡ªå‹•é‡å•Ÿ

**æ¶æ§‹å„ªå‹¢:**
- è®€å¯«åˆ†é›¢ (FastAPI å¯«å…¥ Redis, Worker å¯«å…¥ DB)
- ç•°æ­¥è™•ç† (ç«‹å³è¿”å›ï¼ŒèƒŒæ™¯è™•ç†)
- æ‰¹æ¬¡å„ªåŒ– (æ¸›å°‘è³‡æ–™åº« I/O)
- è² è¼‰å¹³è¡¡ (Nginx åˆ†æ•£æµé‡)

é€™ç¨®è¨­è¨ˆè®“ç³»çµ±èƒ½ç©©å®šè™•ç† **~23,895 logs/second** çš„é«˜è² è¼‰ï¼ŒåŒæ™‚ä¿æŒä½å»¶é² (P95 ~60ms) èˆ‡é›¶éŒ¯èª¤ç‡ã€‚
