"""
å£“åŠ›æ¸¬è©¦è…³æœ¬ - æ¨¡æ“¬ 100 å°è¨­å‚™ä½µç™¼ç™¼é€æ—¥èªŒ
"""
import asyncio
import aiohttp
import time
import random
import json
from datetime import datetime, timedelta
from typing import List
import sys
import os

# æ–°å¢ï¼šæ•´åˆ Prometheus æŸ¥è©¢åŠŸèƒ½
try:
    from prometheus_api_client import PrometheusConnect
    PROMETHEUS_AVAILABLE = True
except ImportError:
    PROMETHEUS_AVAILABLE = False
    print("âš ï¸  è­¦å‘Š: prometheus_api_client æœªå®‰è£ï¼ŒPrometheus æŒ‡æ¨™æŸ¥è©¢åŠŸèƒ½å°‡è¢«åœç”¨")

# ==========================================
# æ¸¬è©¦é…ç½®
# ==========================================
# BASE_URL = "http://localhost:8080"  # åŸå§‹ç«¯å£è¨­å®š
BASE_URL = "http://localhost:18723"  # Nginx ç«¯é»ï¼ˆå°æ‡‰ docker-compose.yml é…ç½®ï¼‰

# æ–°å¢ï¼šPrometheus é…ç½®
PROMETHEUS_URL = "http://localhost:9090"  # Prometheus æœå‹™ URL

# ==========================================
# æ–¹æ¡ˆ A: å»¶é•·å–®æ¬¡æ¸¬è©¦æ™‚é–“é…ç½®ï¼ˆæ¨è–¦ï¼‰
# ==========================================
# NUM_DEVICES = 100                   # åŸå§‹è¨­å‚™æ•¸é‡ (å–®æ¬¡æ¸¬è©¦ ~0.8 ç§’ï¼Œå³°å€¼ 2,483 req/s)
NUM_DEVICES = 100                   # å¢åŠ è¨­å‚™æ•¸é‡è®“å–®æ¬¡æ¸¬è©¦ç´„ 3 ç§’ï¼ˆå³°å€¼ä»ç¶­æŒ ~2,500 req/sï¼‰
LOGS_PER_DEVICE = 100               # æ¯å°è¨­å‚™ç™¼é€çš„æ—¥èªŒæ•¸

CONCURRENT_LIMIT = 200              # æé«˜ä¸¦ç™¼ä»¥é…åˆæ›´å°çš„æ‰¹æ¬¡

# BATCH_SIZE = 100                    # åŸå§‹æ‰¹æ¬¡å¤§å°ï¼ˆP95 ~316msï¼‰
BATCH_SIZE = 5                     # æ¸›å°æ‰¹æ¬¡å¤§å°ä»¥é™ä½ P95 å›æ‡‰æ™‚é–“
USE_BATCH_API = True               # æ˜¯å¦ä½¿ç”¨æ‰¹é‡ APIï¼ˆæ–°å¢ï¼‰

# æ–°å¢ï¼šå¾ªç’°æ¸¬è©¦é…ç½®
NUM_ITERATIONS = 50               # æ¸¬è©¦åŸ·è¡Œçš„å¾ªç’°æ¬¡æ•¸ï¼ˆé è¨­ 1 æ¬¡ï¼‰
# ITERATION_INTERVAL = 1            # åŸè¨­å®šï¼š1 ç§’é–“éš”ï¼ˆå·²æ£„ç”¨ï¼Œå°è‡´æ•¸æ“šé‡ç–Šï¼‰
ITERATION_INTERVAL = 5              # å„ªåŒ–å¾Œï¼š5 ç§’é–“éš”ï¼ˆé¿å…æ•¸æ“šé‡ç–Šï¼Œé…åˆ irate[5s] ç›£æ§ï¼‰

LOG_LEVELS = ["DEBUG", "INFO", "WARNING", "ERROR", "CRITICAL"]
LOG_MESSAGES = [
    "ç³»çµ±æ­£å¸¸é‹è¡Œ",
    "è¨˜æ†¶é«”ä½¿ç”¨ç‡: {usage}%",
    "CPU æº«åº¦: {temp}Â°C",
    "ç¶²è·¯é€£ç·šç•°å¸¸",
    "è³‡æ–™åº«æŸ¥è©¢è¶…æ™‚",
    "æª”æ¡ˆè®€å–å¤±æ•—",
    "æ„Ÿæ¸¬å™¨è®€æ•¸ç•°å¸¸",
    "æ”å½±æ©Ÿç•«é¢æ¨¡ç³Š",
    "ç¡¬ç¢Ÿç©ºé–“ä¸è¶³",
    "è¨­å‚™é‡æ–°å•Ÿå‹•"
]

# ==========================================
# æ–°å¢ï¼šPrometheus æŒ‡æ¨™æŸ¥è©¢å™¨é¡åˆ¥
# ==========================================
class PrometheusMetricsQuerier:
    """
    Prometheus æŒ‡æ¨™æŸ¥è©¢å™¨ï¼ˆæ•´åˆè‡ª query_prometheus_metrics.pyï¼‰
    """
    def __init__(self, prometheus_url=PROMETHEUS_URL):
        """
        åˆå§‹åŒ– Prometheus é€£æ¥

        Args:
            prometheus_url (str): Prometheus æœå‹™çš„ URL
        """
        if not PROMETHEUS_AVAILABLE:
            self.prometheus = None
            return

        try:
            self.prometheus = PrometheusConnect(url=prometheus_url, disable_ssl=True)
            self.prometheus_url = prometheus_url
        except Exception as e:
            print(f"âš ï¸  ç„¡æ³•é€£æ¥åˆ° Prometheus: {e}")
            self.prometheus = None

    def test_connection(self):
        """æ¸¬è©¦èˆ‡ Prometheus çš„é€£æ¥"""
        if not self.prometheus:
            return False

        try:
            # å˜—è©¦ç²å–ä¸€å€‹åŸºæœ¬æŒ‡æ¨™ä¾†æ¸¬è©¦é€£æ¥
            result = self.prometheus.get_current_metric_value("up")
            return True
        except Exception as e:
            print(f"âš ï¸  ç„¡æ³•é€£æ¥åˆ° Prometheus: {e}")
            return False

    def query_test_metrics(self, start_time, end_time, batch_size=BATCH_SIZE):
        """
        æŸ¥è©¢æ¸¬è©¦æœŸé–“çš„ Prometheus æŒ‡æ¨™

        Args:
            start_time (datetime): æ¸¬è©¦é–‹å§‹æ™‚é–“
            end_time (datetime): æ¸¬è©¦çµæŸæ™‚é–“
            batch_size (int): æ‰¹æ¬¡å¤§å°

        Returns:
            dict: åŒ…å«æŸ¥è©¢çµæœçš„å­—å…¸
        """
        if not self.prometheus:
            return {"error": "Prometheus ä¸å¯ç”¨"}

        metrics = {}

        try:
            # ç²å–ç«¯é»æ¨™ç±¤åç¨±
            all_requests_result = self.prometheus.get_current_metric_value("http_requests_total")
            endpoint_label = 'endpoint'
            if all_requests_result:
                sample_labels = all_requests_result[0].get('metric', {})
                endpoint_label = 'endpoint' if 'endpoint' in sample_labels else 'handler' if 'handler' in sample_labels else 'endpoint'
        except:
            endpoint_label = 'endpoint'

        # æŸ¥è©¢æ™‚é–“ç¯„åœå…§çš„æŒ‡æ¨™
        try:
            # QPS (æ‰€æœ‰ç«¯é»)
            qps_result = self.prometheus.custom_query_range(
                query='rate(http_requests_total[1m])',
                start_time=start_time,
                end_time=end_time,
                step='1s'
            )

            # è¨ˆç®—æœ€å¤§å’Œå¹³å‡ QPS
            max_qps_values = []
            for result in qps_result:
                if 'values' in result:
                    values = [float(value[1]) for value in result['values'] if value[1] not in ['NaN', None]]
                    if values:
                        max_qps_values.extend(values)

            metrics['qps'] = {
                'max': max(max_qps_values, default=0) if max_qps_values else 0,
                'avg': sum(max_qps_values) / len(max_qps_values) if max_qps_values else 0
            }
        except Exception as e:
            print(f"âš ï¸  æŸ¥è©¢ QPS æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            metrics['qps'] = {'max': 0, 'avg': 0}

        try:
            # æ‰¹é‡ç«¯é» QPS
            qps_batch_query = f'rate(http_requests_total{{{endpoint_label}="/api/logs/batch"}}[1m])'
            qps_batch_result = self.prometheus.custom_query_range(
                query=qps_batch_query,
                start_time=start_time,
                end_time=end_time,
                step='1s'
            )

            max_qps_batch_values = []
            for result in qps_batch_result:
                if 'values' in result:
                    values = [float(value[1]) for value in result['values'] if value[1] not in ['NaN', None]]
                    if values:
                        max_qps_batch_values.extend(values)

            metrics['qps_batch'] = {
                'max': max(max_qps_batch_values, default=0) if max_qps_batch_values else 0,
                'avg': sum(max_qps_batch_values) / len(max_qps_batch_values) if max_qps_batch_values else 0
            }
        except Exception as e:
            print(f"âš ï¸  æŸ¥è©¢æ‰¹é‡ç«¯é» QPS æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            metrics['qps_batch'] = {'max': 0, 'avg': 0}

        try:
            # ååé‡ (Logs/s)
            throughput_query = f'rate(http_requests_total{{{endpoint_label}="/api/logs/batch"}}[1m]) * {batch_size}'
            throughput_result = self.prometheus.custom_query_range(
                query=throughput_query,
                start_time=start_time,
                end_time=end_time,
                step='1s'
            )

            max_throughput_values = []
            for result in throughput_result:
                if 'values' in result:
                    values = [float(value[1]) for value in result['values'] if value[1] not in ['NaN', None]]
                    if values:
                        max_throughput_values.extend(values)

            metrics['throughput'] = {
                'max': max(max_throughput_values, default=0) if max_throughput_values else 0,
                'avg': sum(max_throughput_values) / len(max_throughput_values) if max_throughput_values else 0
            }
        except Exception as e:
            print(f"âš ï¸  æŸ¥è©¢ååé‡æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            metrics['throughput'] = {'max': 0, 'avg': 0}

        try:
            # P95 éŸ¿æ‡‰æ™‚é–“
            p95_query = 'histogram_quantile(0.95, rate(http_request_duration_seconds_bucket[5m]))'
            p95_result = self.prometheus.custom_query_range(
                query=p95_query,
                start_time=start_time,
                end_time=end_time,
                step='1s'
            )

            p95_values = []
            for result in p95_result:
                if 'values' in result:
                    values = [float(value[1]) * 1000 for value in result['values'] if value[1] not in ['NaN', None]]  # è½‰æ›ç‚º ms
                    if values:
                        p95_values.extend(values)

            metrics['p95_response_time'] = {
                'max': max(p95_values, default=0) if p95_values else 0,
                'avg': sum(p95_values) / len(p95_values) if p95_values else 0
            }
        except Exception as e:
            print(f"âš ï¸  æŸ¥è©¢ P95 éŸ¿æ‡‰æ™‚é–“æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            metrics['p95_response_time'] = {'max': 0, 'avg': 0}

        try:
            # P99 éŸ¿æ‡‰æ™‚é–“
            p99_query = 'histogram_quantile(0.99, rate(http_request_duration_seconds_bucket[5m]))'
            p99_result = self.prometheus.custom_query_range(
                query=p99_query,
                start_time=start_time,
                end_time=end_time,
                step='1s'
            )

            p99_values = []
            for result in p99_result:
                if 'values' in result:
                    values = [float(value[1]) * 1000 for value in result['values'] if value[1] not in ['NaN', None]]  # è½‰æ›ç‚º ms
                    if values:
                        p99_values.extend(values)

            metrics['p99_response_time'] = {
                'max': max(p99_values, default=0) if p99_values else 0,
                'avg': sum(p99_values) / len(p99_values) if p99_values else 0
            }
        except Exception as e:
            print(f"âš ï¸  æŸ¥è©¢ P99 éŸ¿æ‡‰æ™‚é–“æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            metrics['p99_response_time'] = {'max': 0, 'avg': 0}

        try:
            # éŒ¯èª¤ç‡
            error_rate_query = 'rate(http_requests_total{status=~"5..|4.."}[1m])'
            error_rate_result = self.prometheus.custom_query_range(
                query=error_rate_query,
                start_time=start_time,
                end_time=end_time,
                step='1s'
            )

            error_rate_values = []
            for result in error_rate_result:
                if 'values' in result:
                    values = [float(value[1]) for value in result['values'] if value[1] not in ['NaN', None]]
                    if values:
                        error_rate_values.extend(values)

            metrics['error_rate'] = {
                'max': max(error_rate_values, default=0) if error_rate_values else 0,
                'avg': sum(error_rate_values) / len(error_rate_values) if error_rate_values else 0
            }
        except Exception as e:
            print(f"âš ï¸  æŸ¥è©¢éŒ¯èª¤ç‡æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            metrics['error_rate'] = {'max': 0, 'avg': 0}

        return metrics

# ==========================================
# ç”Ÿæˆæ¸¬è©¦è³‡æ–™
# ==========================================
def generate_log_data(device_id: str, log_num: int) -> dict:
    """
    ç”Ÿæˆéš¨æ©Ÿæ—¥èªŒè³‡æ–™
    """
    log_level = random.choice(LOG_LEVELS)
    message_template = random.choice(LOG_MESSAGES)

    # æ ¹æ“šè¨Šæ¯æ¨¡æ¿å¡«å…¥è®Šæ•¸
    if "{usage}" in message_template:
        message = message_template.format(usage=random.randint(50, 95))
    elif "{temp}" in message_template:
        message = message_template.format(temp=random.randint(40, 85))
    else:
        message = message_template

    return {
        "device_id": device_id,
        "log_level": log_level,
        "message": f"{message} (#{log_num})",
        "log_data": {
            "test_id": log_num,
            "timestamp": datetime.now().isoformat(),
            "random_value": random.random(),
            "sequence": log_num
        }
    }

# ==========================================
# ç™¼é€å–®ç­†æ—¥èªŒ
# ==========================================
async def send_log(session: aiohttp.ClientSession, device_id: str, log_num: int) -> dict:
    """
    ç™¼é€å–®ç­†æ—¥èªŒåˆ° API

    è¿”å›ï¼š
        dict: {
            "success": bool,
            "response_time": float,
            "status": int,
            "error": str or None
        }
    """
    url = f"{BASE_URL}/api/log"
    log_data = generate_log_data(device_id, log_num)

    start_time = time.time()

    try:
        async with session.post(url, json=log_data, timeout=aiohttp.ClientTimeout(total=10)) as response:
            response_time = (time.time() - start_time) * 1000  # è½‰æ›ç‚ºæ¯«ç§’

            if response.status == 200:
                return {
                    "success": True,
                    "response_time": response_time,
                    "status": response.status,
                    "error": None,
                    "count": 1
                }
            else:
                return {
                    "success": False,
                    "response_time": response_time,
                    "status": response.status,
                    "error": await response.text(),
                    "count": 1
                }

    except asyncio.TimeoutError:
        return {
            "success": False,
            "response_time": (time.time() - start_time) * 1000,
            "status": 0,
            "error": "è«‹æ±‚è¶…æ™‚",
            "count": 1
        }
    except Exception as e:
        return {
            "success": False,
            "response_time": (time.time() - start_time) * 1000,
            "status": 0,
            "error": str(e),
            "count": 1
        }

# ==========================================
# ç™¼é€æ‰¹é‡æ—¥èªŒï¼ˆæ–°å¢é«˜æ•ˆèƒ½ç«¯é»ï¼‰
# ==========================================
async def send_batch_logs(session: aiohttp.ClientSession, logs: List[dict]) -> dict:
    """
    æ‰¹é‡ç™¼é€æ—¥èªŒåˆ° APIï¼ˆä½¿ç”¨æ‰¹é‡ç«¯é»ï¼‰

    è¿”å›ï¼š
        dict: {
            "success": bool,
            "response_time": float,
            "status": int,
            "error": str or None,
            "count": int
        }
    """
    url = f"{BASE_URL}/api/logs/batch"
    batch_data = {"logs": logs}

    start_time = time.time()

    try:
        async with session.post(url, json=batch_data, timeout=aiohttp.ClientTimeout(total=30)) as response:
            response_time = (time.time() - start_time) * 1000

            if response.status == 200:
                return {
                    "success": True,
                    "response_time": response_time,
                    "status": response.status,
                    "error": None,
                    "count": len(logs)
                }
            else:
                return {
                    "success": False,
                    "response_time": response_time,
                    "status": response.status,
                    "error": await response.text(),
                    "count": len(logs)
                }

    except asyncio.TimeoutError:
        return {
            "success": False,
            "response_time": (time.time() - start_time) * 1000,
            "status": 0,
            "error": "è«‹æ±‚è¶…æ™‚",
            "count": len(logs)
        }
    except Exception as e:
        return {
            "success": False,
            "response_time": (time.time() - start_time) * 1000,
            "status": 0,
            "error": str(e),
            "count": len(logs)
        }

# ==========================================
# æ‰¹æ¬¡ç™¼é€æ—¥èªŒ
# ==========================================
async def batch_send_logs(
    session: aiohttp.ClientSession,
    device_id: str,
    num_logs: int,
    semaphore: asyncio.Semaphore
) -> tuple[List[dict], List[dict]]:
    """
    æ‰¹æ¬¡ç™¼é€æ—¥èªŒï¼ˆä½¿ç”¨ä¿¡è™Ÿé‡æ§åˆ¶ä¸¦ç™¼ï¼‰
    Returns:
        tuple: (results, all_logs) - resultsåŒ…å«APIéŸ¿æ‡‰ï¼Œall_logsåŒ…å«ç™¼é€çš„æ—¥èªŒ
    """
    # ç”Ÿæˆæ‰€æœ‰æ—¥èªŒ
    all_logs = [generate_log_data(device_id, log_num) for log_num in range(num_logs)]

    if USE_BATCH_API:
        # ä½¿ç”¨æ‰¹é‡ APIï¼ˆé«˜æ•ˆèƒ½æ¨¡å¼ï¼‰
        # å°‡æ—¥èªŒåˆ†æˆå¤šå€‹å°æ‰¹æ¬¡ç™¼é€
        results = []

        # æŒ‰ BATCH_SIZE åˆ†å‰²æˆå¤šå€‹æ‰¹æ¬¡
        for i in range(0, len(all_logs), BATCH_SIZE):
            batch = all_logs[i:i + BATCH_SIZE]
            async with semaphore:
                result = await send_batch_logs(session, batch)
                results.append(result)

        # ä¿®æ”¹ï¼šè¿”å›çµæœå’Œç”Ÿæˆçš„æ—¥èªŒæ•¸æ“š
        return results, all_logs
    else:
        # åŸå§‹å–®ç­†ç™¼é€æ¨¡å¼
        async def send_with_semaphore(log_num: int) -> dict:
            async with semaphore:
                return await send_log(session, device_id, log_num)

        tasks = [send_with_semaphore(log_num) for log_num in range(num_logs)]
        results = await asyncio.gather(*tasks)

        # ä¿®æ”¹ï¼šè¿”å›çµæœå’Œç”Ÿæˆçš„æ—¥èªŒæ•¸æ“š
        return results, all_logs

# ==========================================
# ä¸»è¦å£“åŠ›æ¸¬è©¦
# ==========================================
async def stress_test(
    num_devices: int = NUM_DEVICES,
    logs_per_device: int = LOGS_PER_DEVICE,
    concurrent_limit: int = CONCURRENT_LIMIT,
    # æ–°å¢åƒæ•¸ï¼šå¾ªç’°æ¬¡æ•¸ï¼ˆé è¨­ 1 æ¬¡ï¼Œä¿æŒå‘å¾Œç›¸å®¹ï¼‰
    iteration: int = 1,
    # æ–°å¢åƒæ•¸ï¼šç•¶å‰å¾ªç’°çš„ç·¨è™Ÿï¼ˆç”¨æ–¼é¡¯ç¤ºï¼‰
    current_iteration: int = 1
):
    """
    åŸ·è¡Œå£“åŠ›æ¸¬è©¦

    åƒæ•¸ï¼š
        num_devices: è¨­å‚™æ•¸é‡
        logs_per_device: æ¯å°è¨­å‚™ç™¼é€çš„æ—¥èªŒæ•¸
        concurrent_limit: ä¸¦ç™¼é™åˆ¶
        iteration: ç¸½å¾ªç’°æ¬¡æ•¸ï¼ˆæ–°å¢ï¼‰
        current_iteration: ç•¶å‰å¾ªç’°ç·¨è™Ÿï¼ˆæ–°å¢ï¼‰
    """
    # ==========================================
    # åŸæ¸¬è©¦æ¨™é¡Œè¼¸å‡ºï¼ˆå·²ç§»é™¤ï¼‰
    # åŸç¨‹å¼ç¢¼ï¼šè©³ç´°çš„æ¸¬è©¦é…ç½®è¼¸å‡ºå·²è¢«ç§»é™¤ï¼Œæ”¹ç‚ºç°¡æ½”çš„é€²åº¦é¡¯ç¤º
    # ==========================================

    # å»ºç«‹ä¿¡è™Ÿé‡æ§åˆ¶ä¸¦ç™¼
    semaphore = asyncio.Semaphore(concurrent_limit)

    # è¨˜éŒ„é–‹å§‹æ™‚é–“
    start_time = time.time()

    # å»ºç«‹ HTTP Session
    connector = aiohttp.TCPConnector(limit=concurrent_limit, limit_per_host=concurrent_limit)
    timeout = aiohttp.ClientTimeout(total=300)  # ç¸½è¶…æ™‚ 5 åˆ†é˜

    async with aiohttp.ClientSession(connector=connector, timeout=timeout) as session:
        # ç‚ºæ¯å°è¨­å‚™å»ºç«‹ä»»å‹™
        device_tasks = []

        for device_num in range(num_devices):
            # ä¿®æ”¹ï¼šåŠ å…¥ 'opt_' å‰ç¶´ä»¥å€åˆ†å„ªåŒ–ç‰ˆæ¸¬è©¦è³‡æ–™
            device_id = f"opt_device_{device_num:03d}"
            task = batch_send_logs(session, device_id, logs_per_device, semaphore)
            device_tasks.append(task)

        # åŸè¼¸å‡ºï¼šprint("â³ é–‹å§‹ç™¼é€æ—¥èªŒ...") å·²ç§»é™¤

        # ç­‰å¾…æ‰€æœ‰ä»»å‹™å®Œæˆ
        all_results = await asyncio.gather(*device_tasks)

    # è¨ˆç®—ç¸½è€—æ™‚
    total_time = time.time() - start_time

    # æ•´ç†çµæœ - ç¾åœ¨æ¯å€‹è¨­å‚™ä»»å‹™è¿”å› (results, logs)
    all_responses = []
    all_sent_logs = []  # ä¿®æ”¹ï¼šæ”¶é›†æ‰€æœ‰è¨­å‚™ç™¼é€çš„æ—¥èªŒæ•¸æ“š

    for device_results, device_logs in all_results:
        all_responses.extend(device_results)
        all_sent_logs.extend(device_logs)  # ä¿®æ”¹ï¼šæ”¶é›†æ—¥èªŒç”¨æ–¼å¾ŒçºŒåŒ¯å‡º

    # çµ±è¨ˆè³‡æ–™ï¼ˆè€ƒæ…®æ‰¹é‡æ¨¡å¼ï¼‰
    total_requests = len(all_responses)
    successful_requests = sum(1 for r in all_responses if r["success"])
    failed_requests = total_requests - successful_requests
    # è¨ˆç®—å¯¦éš›æ—¥èªŒæ•¸é‡ï¼ˆæ‰¹é‡æ¨¡å¼ä¸‹ä¸€å€‹è«‹æ±‚åŒ…å«å¤šç­†æ—¥èªŒï¼‰
    total_logs_sent = sum(r.get("count", 1) for r in all_responses)
    successful_logs = sum(r.get("count", 1) for r in all_responses if r["success"])

    response_times = [r["response_time"] for r in all_responses if r["success"]]

    if response_times:
        avg_response_time = sum(response_times) / len(response_times)
        min_response_time = min(response_times)
        max_response_time = max(response_times)

        # è¨ˆç®—ç™¾åˆ†ä½æ•¸
        sorted_times = sorted(response_times)
        p50 = sorted_times[int(len(sorted_times) * 0.50)]
        p95 = sorted_times[int(len(sorted_times) * 0.95)]
        p99 = sorted_times[int(len(sorted_times) * 0.99)]
    else:
        avg_response_time = 0
        min_response_time = 0
        max_response_time = 0
        p50 = p95 = p99 = 0

    # ååé‡æŒ‰å¯¦éš›æ—¥èªŒæ•¸è¨ˆç®—ï¼ˆè€Œéè«‹æ±‚æ•¸ï¼‰
    throughput = successful_logs / total_time if total_time > 0 else 0

    # è¨ˆç®— QPSï¼ˆè«‹æ±‚æ•¸/ç§’ï¼‰
    qps = successful_requests / total_time if total_time > 0 else 0

    # ==========================================
    # åŸè¼¸å‡ºé‚è¼¯ï¼ˆå·²ç§»é™¤ï¼‰
    # åŸç¨‹å¼ç¢¼ï¼šè©³ç´°çš„æ§åˆ¶å°è¼¸å‡ºå·²è¢«ç§»é™¤ï¼Œæ”¹ç‚ºåœ¨æ¸¬è©¦çµæŸå¾Œçµ±ä¸€åŒ¯å‡º JSON
    # ==========================================

    # éŒ¯èª¤åˆ†æï¼ˆç”¨æ–¼ JSON åŒ¯å‡ºï¼‰
    error_types = {}
    if failed_requests > 0:
        for r in all_responses:
            if not r["success"]:
                error = r["error"] or f"HTTP {r['status']}"
                error_types[error] = error_types.get(error, 0) + 1

    # åˆ¤æ–·æ˜¯å¦é”åˆ°ç›®æ¨™
    target_throughput = 10000  # ç›®æ¨™ï¼š10,000 logs/ç§’
    target_p95 = 100           # ç›®æ¨™ï¼šP95 < 100ms

    # ä¿®æ”¹ï¼šè¿”å›å®Œæ•´æ¸¬è©¦çµæœä¾› JSON åŒ¯å‡ºä½¿ç”¨
    return {
        "iteration": current_iteration,
        "total_iterations": iteration,
        "timestamp": datetime.now().isoformat(),
        "config": {
            "num_devices": num_devices,
            "logs_per_device": logs_per_device,
            "total_logs": num_devices * logs_per_device,
            "concurrent_limit": concurrent_limit,
            "batch_size": BATCH_SIZE,
            "use_batch_api": USE_BATCH_API,
            "base_url": BASE_URL
        },
        "timing": {
            "total_time": round(total_time, 2),
        },
        "requests": {
            "total_requests": total_requests,
            "successful_requests": successful_requests,
            "failed_requests": failed_requests,
            "success_rate": round(successful_requests/total_requests*100, 2) if total_requests > 0 else 0
        },
        "logs": {
            "total_logs_sent": total_logs_sent,
            "successful_logs": successful_logs,
            "success_rate": round(successful_logs/total_logs_sent*100, 2) if total_logs_sent > 0 else 0
        },
        "performance": {
            "qps": round(qps, 2),
            "throughput": round(throughput, 2),
            "avg_response_time": round(avg_response_time, 2),
            "min_response_time": round(min_response_time, 2),
            "max_response_time": round(max_response_time, 2)
        },
        "percentiles": {
            "p50": round(p50, 2),
            "p95": round(p95, 2),
            "p99": round(p99, 2)
        },
        "errors": error_types,
        "targets": {
            "throughput": {
                "target": target_throughput,
                "actual": round(throughput, 2),
                "achieved": throughput >= target_throughput
            },
            "p95_response_time": {
                "target": target_p95,
                "actual": round(p95, 2),
                "achieved": p95 <= target_p95
            },
            "zero_failures": {
                "achieved": failed_requests == 0,
                "failed_count": failed_requests
            }
        },
        "sent_logs_data": all_sent_logs  # ä¿®æ”¹ï¼šåŒ…å«é€™è¼ªæ¸¬è©¦ç”Ÿæˆçš„æ‰€æœ‰æ—¥èªŒç”¨æ–¼åŒ¯å‡º
    }

# ==========================================
# æŸ¥è©¢æ¸¬è©¦
# ==========================================
async def query_test(device_id: str = "device_000"):
    """
    æ¸¬è©¦æŸ¥è©¢ API
    """
    print(f"\nğŸ“– æŸ¥è©¢æ¸¬è©¦: {device_id}")
    print("-" * 70)

    url = f"{BASE_URL}/api/logs/{device_id}?limit=10"

    start_time = time.time()

    async with aiohttp.ClientSession() as session:
        async with session.get(url) as response:
            response_time = (time.time() - start_time) * 1000

            if response.status == 200:
                data = await response.json()
                print(f"âœ… æŸ¥è©¢æˆåŠŸ")
                print(f"  â€¢ å›æ‡‰æ™‚é–“: {response_time:.2f} ms")
                print(f"  â€¢ è³‡æ–™ä¾†æº: {data.get('source', 'unknown')}")
                print(f"  â€¢ æ—¥èªŒæ•¸é‡: {data.get('total', 0)}")
            else:
                print(f"âŒ æŸ¥è©¢å¤±æ•—: HTTP {response.status}")

# ==========================================
# åŸåŒ¯å‡ºæ¸¬è©¦è¼ªæ¬¡æ—¥èªŒå‡½æ•¸ï¼ˆå·²ç§»é™¤ï¼‰
# ==========================================
# åŸç¨‹å¼ç¢¼ï¼šexport_logs_for_iteration å‡½æ•¸å·²è¢«ç§»é™¤
# æ”¹ç‚ºåœ¨ main() çµæŸæ™‚çµ±ä¸€åŒ¯å‡ºæ‰€æœ‰æ¸¬è©¦çµæœç‚ºå–®ä¸€ JSON æª”æ¡ˆ

# ==========================================
# åŒ¯å‡ºååé‡æŒ‡æ¨™
# ==========================================
def export_metrics(test_start_time: datetime, test_end_time: datetime):
    """
    æ¸¬è©¦å®Œæˆå¾Œï¼ŒåŒ¯å‡º Prometheus ååé‡æŒ‡æ¨™

    Args:
        test_start_time: æ¸¬è©¦é–‹å§‹æ™‚é–“
        test_end_time: æ¸¬è©¦çµæŸæ™‚é–“
    """
    print("\n" + "=" * 70)
    print("  ğŸ“Š åŒ¯å‡º Prometheus ååé‡æŒ‡æ¨™")
    print("=" * 70)

    # å–å¾— export_throughput_metrics.py çš„è·¯å¾‘
    script_dir = os.path.dirname(os.path.abspath(__file__))
    project_root = os.path.dirname(script_dir)
    export_script = os.path.join(
        project_root, "monitoring", "scripts", "export_throughput_metrics.py"
    )

    if not os.path.exists(export_script):
        print(f"âš ï¸  æ‰¾ä¸åˆ°åŒ¯å‡ºè…³æœ¬: {export_script}")
        return

    # å»ºç«‹ test_file è³‡æ–™å¤¾ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
    test_file_dir = os.path.join(project_root, "test_file")
    os.makedirs(test_file_dir, exist_ok=True)

    # åŒ¯å…¥åŒ¯å‡ºå·¥å…·
    sys.path.insert(0, os.path.join(project_root, "monitoring", "scripts"))
    try:
        from export_throughput_metrics import PrometheusExporter

        # å»ºç«‹ exporter
        exporter = PrometheusExporter()

        # ä¿®æ”¹ï¼šå›ºå®šè¼¸å‡ºæª”åï¼ˆä¸å«æ—¥æœŸæ™‚é–“ï¼‰ï¼Œå­˜æ”¾åˆ° test_file è³‡æ–™å¤¾
        # åŸç¨‹å¼ç¢¼ï¼ˆå·²è¨»é‡‹ï¼‰ï¼š
        # timestamp_str = test_start_time.strftime("%Y%m%d_%H%M%S")
        # output_file = os.path.join(
        #     test_file_dir, f"throughput_metrics_{timestamp_str}.csv"
        # )
        output_file = os.path.join(
            test_file_dir, "monitoring_throughput_metrics.csv"
        )

        print(f"â±ï¸  æ¸¬è©¦æ™‚é–“ç¯„åœ:")
        print(f"   é–‹å§‹: {test_start_time}")
        print(f"   çµæŸ: {test_end_time}")
        print(f"   è¼¸å‡º: {output_file}")
        print()

        # åŸ·è¡ŒåŒ¯å‡º
        exporter.export_throughput_metrics(
            test_start_time, test_end_time, output_file
        )

        # ä¿®æ”¹ï¼šç§»é™¤ HTTP QPS Top 20 åˆ†æï¼ˆå·²æ”¹ç‚ºç›´æ¥åœ¨ export_throughput_metrics ä¸­é€²è¡Œç¯©é¸ä¸¦è¦†è“‹åŸæª”æ¡ˆï¼‰
        # åŸç¨‹å¼ç¢¼ï¼ˆå·²è¨»é‡‹ï¼‰ï¼š
        # if os.path.exists(output_file):
        #     try:
        #         exporter.filter_http_qps_top20(output_file)
        #     except Exception as e:
        #         print(f"\nâš ï¸  HTTP QPS Top 20 åˆ†æå¤±æ•—: {e}")
        #         print("   ä¸»è¦åŒ¯å‡ºæª”æ¡ˆä¸å—å½±éŸ¿")

    except ImportError as e:
        print(f"âŒ ç„¡æ³•åŒ¯å…¥ export_throughput_metrics: {e}")
    except Exception as e:
        print(f"âŒ åŒ¯å‡ºæŒ‡æ¨™æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
    finally:
        # ç§»é™¤æ–°å¢çš„è·¯å¾‘
        if sys.path[0] == os.path.join(project_root, "monitoring", "scripts"):
            sys.path.pop(0)

# ==========================================
# ä¸»ç¨‹å¼
# ==========================================
async def main():
    """
    ä¸»ç¨‹å¼å…¥å£
    """
    # è¨˜éŒ„æ•´é«”æ¸¬è©¦é–‹å§‹æ™‚é–“ï¼ˆç”¨æ–¼åŒ¯å‡ºæŒ‡æ¨™ï¼‰
    overall_start_time = datetime.now()

    # æ”¶é›†æ‰€æœ‰æ¸¬è©¦çµæœ
    all_test_results = []

    # ä¿®æ”¹ï¼šæ”¯æ´å¤šè¼ªå¾ªç’°æ¸¬è©¦
    for i in range(NUM_ITERATIONS):
        # åŸ·è¡Œå£“åŠ›æ¸¬è©¦ï¼ˆå‚³å…¥å¾ªç’°è³‡è¨Šï¼‰
        result = await stress_test(
            num_devices=NUM_DEVICES,
            logs_per_device=LOGS_PER_DEVICE,
            concurrent_limit=CONCURRENT_LIMIT,
            iteration=NUM_ITERATIONS,  # æ–°å¢ï¼šå‚³å…¥ç¸½å¾ªç’°æ¬¡æ•¸
            current_iteration=i + 1     # æ–°å¢ï¼šå‚³å…¥ç•¶å‰å¾ªç’°ç·¨è™Ÿ
        )

        # æ”¶é›†çµæœï¼ˆä¿ç•™å®Œæ•´æ•¸æ“šä¾›æœ€å¾ŒåŒ¯å‡ºï¼Œä½†ä¸åŒ…å« sent_logs_data ä»¥ç¯€çœå…§å­˜ï¼‰
        result_copy = {k: v for k, v in result.items() if k != 'sent_logs_data'}
        all_test_results.append(result_copy)

        # ç°¡å–®é¡¯ç¤ºé€²åº¦
        print(f"âœ… ç¬¬ {i + 1}/{NUM_ITERATIONS} è¼ªæ¸¬è©¦å®Œæˆ")

        # æ–°å¢ï¼šå¦‚æœä¸æ˜¯æœ€å¾Œä¸€è¼ªï¼Œç­‰å¾…é–“éš”æ™‚é–“
        if i < NUM_ITERATIONS - 1 and ITERATION_INTERVAL > 0:
            print(f"\nâ¸ï¸  ç­‰å¾… {ITERATION_INTERVAL} ç§’å¾Œé–‹å§‹ä¸‹ä¸€è¼ªæ¸¬è©¦...")
            await asyncio.sleep(ITERATION_INTERVAL)

    # è¨ˆç®—æ™‚é–“ç¨€é‡‹ä¿®æ­£å¾Œçš„æŒ‡æ¨™
    if NUM_ITERATIONS > 1 and ITERATION_INTERVAL > 0:
        print("\n" + "=" * 70)
        print("  ğŸ”¬ æ™‚é–“ç¨€é‡‹ä¿®æ­£åˆ†æ")
        print("=" * 70)

        # è¨ˆç®—ç¸½å·¥ä½œæ™‚é–“å’Œç¸½ç­‰å¾…æ™‚é–“
        total_work_time = sum(r["timing"]["total_time"] for r in all_test_results)
        total_wait_time = ITERATION_INTERVAL * (NUM_ITERATIONS - 1)
        total_elapsed_time = total_work_time + total_wait_time

        # è¨ˆç®—ç¸½æˆåŠŸæ•¸
        total_requests = sum(r["requests"]["successful_requests"] for r in all_test_results)
        total_logs = sum(r["logs"]["successful_logs"] for r in all_test_results)

        # å¯¦éš›æ¸¬é‡çš„å¹³å‡å€¼ï¼ˆå«ç¨€é‡‹ï¼‰
        measured_avg_qps = total_requests / total_elapsed_time
        measured_avg_throughput = total_logs / total_elapsed_time

        # ä¿®æ­£å¾Œçš„å€¼ï¼ˆç´”å·¥ä½œæ™‚é–“ï¼‰
        corrected_qps = total_requests / total_work_time
        corrected_throughput = total_logs / total_work_time

        # å·¥ä½œæ™‚é–“æ¯”ä¾‹
        work_ratio = total_work_time / total_elapsed_time

        print(f"\nâ±ï¸  æ™‚é–“åˆ†æï¼š")
        print(f"  â€¢ ç¸½å·¥ä½œæ™‚é–“: {total_work_time:.2f} ç§’ ({work_ratio*100:.1f}%)")
        print(f"  â€¢ ç¸½ç­‰å¾…æ™‚é–“: {total_wait_time:.2f} ç§’ ({(1-work_ratio)*100:.1f}%)")
        print(f"  â€¢ ç¸½ç¶“éæ™‚é–“: {total_elapsed_time:.2f} ç§’")

        print(f"\nğŸ“Š æŒ‡æ¨™å°æ¯”ï¼š")
        print(f"  â€¢ å¯¦æ¸¬å¹³å‡ QPS: {measured_avg_qps:.2f} req/s (å«ç¨€é‡‹)")
        print(f"  â€¢ ä¿®æ­£å¾Œ QPS: {corrected_qps:.2f} req/s (ç´”å·¥ä½œæ™‚é–“)")
        print(f"  â€¢ ç¨€é‡‹æ¯”ä¾‹: {work_ratio:.2%}")

        print(f"\n  â€¢ å¯¦æ¸¬å¹³å‡ååé‡: {measured_avg_throughput:.2f} logs/s (å«ç¨€é‡‹)")
        print(f"  â€¢ ä¿®æ­£å¾Œååé‡: {corrected_throughput:.2f} logs/s (ç´”å·¥ä½œæ™‚é–“)")

        print(f"\nâœ… é©—è­‰æ›ç®—å…¬å¼ï¼š")
        calculated_throughput = corrected_qps * BATCH_SIZE
        throughput_match = abs(calculated_throughput - corrected_throughput) / corrected_throughput < 0.01
        print(f"  â€¢ ä¿®æ­£å¾Œååé‡ = ä¿®æ­£å¾Œ QPS Ã— BATCH_SIZE")
        print(f"  â€¢ {corrected_throughput:.2f} â‰ˆ {corrected_qps:.2f} Ã— {BATCH_SIZE}")
        print(f"  â€¢ {corrected_throughput:.2f} â‰ˆ {calculated_throughput:.2f}")
        if throughput_match:
            print(f"  â€¢ âœ… æ›ç®—å…¬å¼é©—è­‰é€šé (èª¤å·® < 1%)")
        else:
            print(f"  â€¢ âš ï¸  æ›ç®—å…¬å¼æœ‰åå·®")

        print(f"\nğŸ’¡ Grafana è§€æ¸¬æç¤ºï¼š")
        print(f"  â€¢ å¦‚æœä½¿ç”¨ rate[30s]ï¼ŒGrafana æœƒé¡¯ç¤º: ~{measured_avg_qps:.0f} req/s (å«ç¨€é‡‹)")
        print(f"  â€¢ å¦‚æœä½¿ç”¨ irate[5s]ï¼ŒGrafana åœ¨å³°å€¼æœŸé–“æœƒé¡¯ç¤º: ~{corrected_qps:.0f} req/s (çœŸå¯¦å³°å€¼)")
        print(f"  â€¢ å…©è€…å·®ç•°ä¾†è‡ªæ™‚é–“ç¨€é‡‹æ•ˆæ‡‰: {work_ratio:.0%} å·¥ä½œæ™‚é–“æ¯”ä¾‹")
        print(f"  â€¢ {ITERATION_INTERVAL}ç§’é–“éš”è¨­è¨ˆï¼šè®“ irate[5s] æ•æ‰å–®æ¬¡æ¸¬è©¦å³°å€¼ï¼Œé¿å…æ•¸æ“šé‡ç–Š")
        print(f"  â€¢ ç¸½å¾ªç’°é€±æœŸ: {total_work_time/NUM_ITERATIONS + ITERATION_INTERVAL:.1f} ç§’ (æ¸¬è©¦ {total_work_time/NUM_ITERATIONS:.1f}s + é–“éš” {ITERATION_INTERVAL}s)")

        print("=" * 70)

    # ç­‰å¾… Worker è™•ç†å®Œæˆ
    print("\nâ³ ç­‰å¾… 5 ç§’è®“ Worker è™•ç†æ—¥èªŒ...")
    await asyncio.sleep(5)

    # åŸ·è¡ŒæŸ¥è©¢æ¸¬è©¦
    # ä¿®æ”¹ï¼šä½¿ç”¨æ–°çš„ device_id å‰ç¶´
    await query_test("opt_device_000")

    # æŸ¥è©¢çµ±è¨ˆè³‡æ–™
    print(f"\nğŸ“Š æŸ¥è©¢ç³»çµ±çµ±è¨ˆ...")
    async with aiohttp.ClientSession() as session:
        async with session.get(f"{BASE_URL}/api/stats") as response:
            if response.status == 200:
                stats = await response.json()
                print(f"  â€¢ ç¸½æ—¥èªŒæ•¸: {stats.get('total_logs', 0):,}")
                print(f"  â€¢ æŒ‰ç­‰ç´šçµ±è¨ˆ:")
                for level, count in stats.get('logs_by_level', {}).items():
                    print(f"    - {level}: {count:,}")

    # ==========================================
    # æ–°å¢ï¼šåŒ¯å‡º Prometheus ååé‡æŒ‡æ¨™
    # ==========================================
    overall_end_time = datetime.now()

    print("\n" + "=" * 70)
    print("â³ ç­‰å¾… 10 ç§’è®“ Prometheus æ”¶é›†å®Œæ•´æŒ‡æ¨™...")
    print("=" * 70)
    await asyncio.sleep(10)

    # åŸ·è¡ŒæŒ‡æ¨™åŒ¯å‡º
    export_metrics(overall_start_time, overall_end_time)

    # ==========================================
    # æ–°å¢ï¼šæŸ¥è©¢ Prometheus æŒ‡æ¨™
    # ==========================================
    prometheus_metrics = None
    if PROMETHEUS_AVAILABLE:
        print("\n" + "=" * 70)
        print("  ğŸ“Š æŸ¥è©¢ Prometheus æŒ‡æ¨™")
        print("=" * 70)

        try:
            querier = PrometheusMetricsQuerier()
            if querier.test_connection():
                print("âœ… é€£æ¥åˆ° Prometheus æˆåŠŸ")
                print("â³ æŸ¥è©¢æ¸¬è©¦æœŸé–“çš„æŒ‡æ¨™...")

                # æŸ¥è©¢æ¸¬è©¦æœŸé–“çš„æŒ‡æ¨™
                prometheus_metrics = querier.query_test_metrics(
                    start_time=overall_start_time,
                    end_time=overall_end_time,
                    batch_size=BATCH_SIZE
                )

                # é¡¯ç¤ºæŸ¥è©¢çµæœæ‘˜è¦
                print("\nğŸ“ˆ Prometheus æŒ‡æ¨™æ‘˜è¦:")
                print(f"  â€¢ QPS (æ‰€æœ‰ç«¯é»): æœ€å¤§ {prometheus_metrics['qps']['max']:.2f} req/s, å¹³å‡ {prometheus_metrics['qps']['avg']:.2f} req/s")
                print(f"  â€¢ QPS (æ‰¹é‡ç«¯é»): æœ€å¤§ {prometheus_metrics['qps_batch']['max']:.2f} req/s, å¹³å‡ {prometheus_metrics['qps_batch']['avg']:.2f} req/s")
                print(f"  â€¢ ååé‡: æœ€å¤§ {prometheus_metrics['throughput']['max']:.2f} logs/s, å¹³å‡ {prometheus_metrics['throughput']['avg']:.2f} logs/s")
                print(f"  â€¢ P95 éŸ¿æ‡‰æ™‚é–“: æœ€å¤§ {prometheus_metrics['p95_response_time']['max']:.2f} ms, å¹³å‡ {prometheus_metrics['p95_response_time']['avg']:.2f} ms")
                print(f"  â€¢ P99 éŸ¿æ‡‰æ™‚é–“: æœ€å¤§ {prometheus_metrics['p99_response_time']['max']:.2f} ms, å¹³å‡ {prometheus_metrics['p99_response_time']['avg']:.2f} ms")
                print(f"  â€¢ éŒ¯èª¤ç‡: æœ€å¤§ {prometheus_metrics['error_rate']['max']:.4f}, å¹³å‡ {prometheus_metrics['error_rate']['avg']:.4f}")
            else:
                print("âš ï¸  ç„¡æ³•é€£æ¥åˆ° Prometheusï¼Œè·³éæŒ‡æ¨™æŸ¥è©¢")
        except Exception as e:
            print(f"âŒ æŸ¥è©¢ Prometheus æŒ‡æ¨™æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
    else:
        print("\nâš ï¸  Prometheus å®¢æˆ¶ç«¯ä¸å¯ç”¨ï¼Œè·³éæŒ‡æ¨™æŸ¥è©¢")

    # ==========================================
    # åŒ¯å‡ºæ‰€æœ‰æ¸¬è©¦çµæœç‚º JSONï¼ˆåŒ…å« Prometheus æŒ‡æ¨™ï¼‰
    # ==========================================
    print("\n" + "=" * 70)
    print("  ğŸ“„ åŒ¯å‡ºæ¸¬è©¦çµæœ")
    print("=" * 70)

    script_dir = os.path.dirname(os.path.abspath(__file__))
    project_root = os.path.dirname(script_dir)
    test_file_dir = os.path.join(project_root, "test_file")

    # å»ºç«‹ test_file è³‡æ–™å¤¾ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
    os.makedirs(test_file_dir, exist_ok=True)

    # ç”¢ç”Ÿè¼¸å‡ºæª”æ¡ˆåç¨±ï¼ˆä½¿ç”¨å›ºå®šåç¨±æˆ–æ™‚é–“æˆ³è¨˜ï¼‰
    timestamp_str = overall_start_time.strftime("%Y%m%d_%H%M%S")
    output_file = os.path.join(test_file_dir, f"stress_test_results_{timestamp_str}.json")

    # æº–å‚™å®Œæ•´çš„æ¸¬è©¦å ±å‘Š
    test_report = {
        "test_summary": {
            "start_time": overall_start_time.isoformat(),
            "end_time": overall_end_time.isoformat(),
            "total_duration": round((overall_end_time - overall_start_time).total_seconds(), 2),
            "num_iterations": NUM_ITERATIONS,
            "iteration_interval": ITERATION_INTERVAL
        },
        "iterations": all_test_results
    }

    # åŒ¯å‡º JSON
    try:
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(test_report, f, ensure_ascii=False, indent=2)

        print(f"âœ… æ¸¬è©¦çµæœå·²åŒ¯å‡ºè‡³: {output_file}")
        print(f"   åŒ…å« {len(all_test_results)} è¼ªæ¸¬è©¦çµæœ")
        print("=" * 70)
    except Exception as e:
        print(f"âŒ åŒ¯å‡ºæ¸¬è©¦çµæœæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
        print("=" * 70)

if __name__ == "__main__":
    asyncio.run(main())
